---
title: 'MoViE: Mobile Diffusion for Video Editing'

authors:
- Adil Karjauv
- Noor Fathima
- Ioannis Lelekas
- Fatih Porikli
- Amir Ghodrati
- admin

date: '2024-12-09'

publishDate: '2024-12-09T11:50:19.106987Z'

publication_types: ['paper-conference']

publication: '*arXiv preprint*'

abstract: Recent progress in diffusion-based video editing has shown remarkable potential for practical applications. However, these methods remain prohibitively expensive and challenging to deploy on mobile devices. In this study, we introduce a series of optimizations that render mobile video editing feasible. Building upon the existing image editing model, we first optimize its architecture and incorporate a lightweight autoencoder. Subsequently, we extend classifier-free guidance distillation to multiple modalities, resulting in a threefold on-device speedup. Finally, we reduce the number of sampling steps to one by introducing a novel adversarial distillation scheme which preserves the controllability of the editing process. Collectively, these optimizations enable video editing at 12 frames per second on mobile devices, while maintaining high quality. Our results are available at https://qualcomm-ai-research.github.io/mobile-video-editing/

tags: [Generative Modeling, Video Generation, Efficient Diffusion Model]

# Display this page in the Featured widget?
featured: true

url_pdf: 'https://arxiv.org/pdf/2412.06578'
url_code: 'https://qualcomm-ai-research.github.io/mobile-video-editing/'
url_poster: ''
url_project: 'https://qualcomm-ai-research.github.io/mobile-video-editing/'
url_slides: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Cover figure'
  focal_point: ''
  preview_only: false
---
